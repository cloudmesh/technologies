## Event Hubs :smiley: :exclamation: fa18-523-57


|          |                                         |
| -------- | --------------------------------------- |
| title    | Event Hubs                              | 
| status   | 10                                      |
| section  | Inter process communication Collectives |
| keywords | Inter process communication Collectives |


Event Hubs [@www-fa18-523-57-event-hubs] is a streaming platform for Big Data, which can process millions of information called events in any second. It can receive, process and store data produced by several distributed services, and can be transformed using any existing analytics tool. Event Hubbs is ideally used for Anomaly detection, archiving data, live reporting, analytics pipelines, application logging and so on. It helps in easier data processing and analytics to gain timely knowledge from the real time data from various sources [@www-fa18-523-57-what-is-event-hub].

Event Hubs provides an event big data pipeline which ensures a proper communication platform between then data or event publishers and their respective consumers. It also allows a stream handling with different characteristics from the traditional ones. Each of the capabilities of Event Hubs is built around a very huge processing scenario. Event Hubs supports various protocols for publishing data events into Kafka ecosystems by Apache [@www-fa18-523-57-event-hub-documentation]. Its key features include the fully managed configuration of PaaS service, it supports real-time processing, its highly scalable, and has key components in architecture which are discussed in brief below. 

Features:

1. Fully Managed Configuration of PaaS service:

   Event Hubs is managed very efficiently that very little management overhead can be observed, and the users can focus more on different aspects of their projects. 
   
2. Real time processing support:

   Event Hubs has a special partition-based processing model which enables different applications process the same stream of the real time data at the same time. It enables capture of almost real-time data as micro-batches in processing which allows for longer retention of the captured data.

3. Scalability:

   Event Hubs can manage and process data from a small data stream to a very huge data stream of Giga or Terabytes of data, so the problem of storage and processing overhead is out of question.

4. Ecosystem:
   
   Event Hubs enables Kafka by Apache into the respective ecosystem to communicate with it seamlessly without having to manage clusters and immediately process the streams of data.

