## HDF :smiley: :exclamation: fa18-523-69


|          |                 |
| -------- | --------------- |
| title    | HDF             | 
| status   | 10              |
| section  | File management |
| keywords | File management |

HDF (Hortonworks DataFlow) provides users a GUI based platform to design 
and build complex dataflows to ingest and analyze data from multiple sources
of streaming data [@fa18-523-69-hortonworks]. In an age where Internet of things
is rapidly gaining importance with each passing day, systems ability to deal with
a large amount of streaming data has become paramount. But dealing with streaming
data brings with it, a lot of challenges. Some of the main aspects while dealing
with real-time data include - Data security, Computational Speed and maintaining 
Data Integrity. There are a few technologies developed specifically to handle 
streaming data. Hortonworks DataFlow (HDF) is one such technology.

> "Hortonworks DataFlow (HDF) is a scalable, real-time streaming analytics   
> platform that ingests, curates and analyzes data for key insights and  
> immediate actionable intelligence" [@fa18-523-69-hortonworks].

While ingesting data in HDF, it is possible for the users to transform and
enrich the data as well. HDF uses Apache Kafka to perform real-time analytics on
extremely large amounts of the streaming data, enabling the users to make faster
decision. HDF is an open source technology, making the setup future-proof. Its
ability to handle a large volume of diversified data means that HDF is used in
multiple sectors to implement IOT solutions. Real-time dataflow management and
provenance eliminates the need to perform any manual sweep to look for any
missing data or any shortcomings in the dataflow. HDF provides what can be
called an end-to-end solution while dealing with streaming data; which means
that, it provides a solution beginning right from data collection, data
security, data transformation, integration from multiple sources and then tops
it all off by deploying Machine learning algorithms to provide actionable
business insights to the end user and it does all of this in real-time. With
GDPR and other regulatory compliance laws, tracking of data lineage has become a
compulsion; HDFs integration of Apache Atlas provides the user with complete
control over data governance [@fa18-523-69-hortonworks].
