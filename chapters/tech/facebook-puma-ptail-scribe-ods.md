## Facebook Puma/Ptail/Scribe/ODS


|          |                                |
| -------- | ------------------------------ |
| title    | Facebook Puma/Ptail/Scribe/ODS | 
| status   | 90                             |
| section  | Streams                        |
| keywords | Streams                        |


     
The real time data Processing at Facebook is carried out using the
technologies like Scribe, Ptail, Puma, and ODS. While designing the
system, facebook primarily focused on the five key decisions that the
system should incorporate which were Ease of Use, Performance,
Fault-tolerance, Scalability, and Correctness.

> "The real time data analytics ecosystem at facebook is designed to
> handle hundreds of Gigabytes of data per second via hundreds of data
> pipelines and this system handles over 200,000 events per second
> with a maximum latency of 30 seconds" [@www-facebook].

Facebook focused on the Seconds
of latency while designing the system and not milliseconds as seconds
are fast enough to for all the use case that needs to be supported,
and it allowed facebook to use persistent message bus for data
transport and this also made the system more fault tolerant and
scalable [@www-facebook]. The large infrastructure of facebook
comprises of hundreds of systems distributed across multiple data
centers that needs a continuous monitoring to track their health and
performance which is done by Operational Data Store
(ODS) [@facebook-paper-2016]. ODS comprises of a time series
database (TSDB), which is a query service, and a detection and
alerting system. ODS's TSDB is built atop the HBase storage
system. Time series data from services running on Facebook hosts is
collected by the ODS write service and written to HBase.

When the data is generated by the user from their devices, an AJAX
request is fired to facebook, and these requests are then written to a
log file using Scribe (distributed data transport system), this
messaging system collects, aggregates, and delivers high volume of log
data with few seconds of latency and high throughput. Scribe stores
the data in the HDFS (Hadoop Distributed File System) in a tailing
fashion, where the new events are stored in log files and the files
are tailed below the current events. The events are then written into
the storage HBase on distributed machines. This makes the data
available for both batch and real-time processing. Ptail is an
internal tool built to aggregate data from multiple Scribe stores. It
then tails the log files and pulls data out for processing. Puma is a
stream processing system which is the real-time aggregation/storage of
data. Puma provides filtering and processing of Scribe streams (with a
few seconds delay), usually Puma batches the storage per 1.5 seconds
on average and when the last flush completes, then only a new batch
starts to avoid the contention issues, which makes it fairly real
time.
     
