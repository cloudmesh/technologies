## LightGBM :o:


|          |          |
| -------- | -------- |
| title    | LightGBM |
| status   | 95       |
| section  | TBD      |
| keywords | TBD      |


ERROR: CITATION PLACEMENT WRONG WE CAN NOT FIGURE OUT IF THIS MEANS
IT IS PROPERLY QUOTED


> ``A fast, distributed, high performance gradient boosting(GBDT,
> GBRT, GBM or MART) framework based on decision tree algorithms, used
> for ranking, classification and many other machine learning
> tasks. It is under the umbrella of the DMTK project of
> Microsoft'' [@hid-sp18-401-lightgbm].



LightGBM is used to implement gradient boosting algorithm in machine
learning with the aim to do so fastly, at the same time not compromising
on high performance. A couple of lines on gradient boosting is necessary
in understanding the context and relevance of LightGBM. Gradient
Boosting is a machine learning technique used to build both regression
and classification models. It is primarily used in building decision
trees. But building gradient boosting models on huge datasets(that
sometimes contain more than 500,000 observations) is computationally
onerous, not so efficient. LightGBM solves this problem and that is why
it is gaining popularity in Machine Learning community and people are
using this in their Kaggle machine learning projects.
